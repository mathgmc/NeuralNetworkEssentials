# Neural Network Essentials with Python
This repository contains Jupyter notebooks that are part of my personal study of neural networks and deep learning. The focus is on understanding key concepts through practical Python implementations.

## Contents
- **01_linear_layer.ipynb**
    - Introduction to linear layers in neural networks.
    - Demonstrates the role of linear transformations in mapping input data to outputs.
- **02_activation_functions.ipynb**
    - Overview of common activation functions such as `ReLU`, sigmoid, and tanh.
    - Explains their importance in introducing non-linearity to neural networks.
- **03_multi_layer_network.ipynb**
    - Introduction to building multi-layer neural networks.
    - Illustrates how to combine layers and activation functions for complex architectures.
    - Explore `torchsummary` lib, that provides information about the number of parameters and the size of the output of each layer.

## Requirements
- Python 3.8 or higher
- Jupyter Notebook
- Required libraries:
```
numpy<2
matplotlib
torch
torchsummary
```
- Install dependencies with:
`pip install numpy matplotlib torch torchsummary`