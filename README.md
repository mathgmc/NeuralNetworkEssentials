# Neural Network Essentials with Python
This repository contains Jupyter notebooks that are part of my personal study of neural networks and deep learning. The focus is on understanding key concepts through practical Python implementations.

## Contents
- **01_linear_layer.ipynb**
    - Introduction to linear layers in neural networks.
    - Demonstrates the role of linear transformations in mapping input data to outputs.
- **02_activation_functions.ipynb**
    - Overview of common activation functions such as `ReLU`, sigmoid, and tanh.
    - Explains their importance in introducing non-linearity to neural networks.
- **03_multi_layer_network.ipynb**
    - Introduction to building multi-layer neural networks.
- **04_loss_functions.ipynb**
    - Introduction to loss functions and some tests with diferents functions
- **05_model_optimization.ipynb**
    - Introduction to optimization
    - Uses Pytorch dataset of wines to train a model
- **06_loading_image_and_training.ipynb**
    - Train a image collection of handwriting to recognize alphanumeric characteres
- **07_predict_bike_rental.ipynb**
    - Loads a external dataset of bike rentals
    - Train a model to predict the number of bike rentals on a given day

## Requirements
- Python 3.8 or higher
- Jupyter Notebook
- Required libraries:
```
numpy<2
matplotlib
torch
torchsummary
```
- Install dependencies with:
`pip install numpy matplotlib torch torchsummary`